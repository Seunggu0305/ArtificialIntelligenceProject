{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework5_2018311840_강승구.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fce6Kxv3v1KX",
        "colab_type": "code",
        "outputId": "5ef9b31d-1138-4035-a4d2-1718e8860ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#dataset\n",
        "transform = transforms.Compose([transforms.Resize((32,32)), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "valid = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "num = len(train)\n",
        "indices = list(range(num))\n",
        "split = int(np.floor(0.1 * num))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=64, sampler=train_sampler)\n",
        "validloader = torch.utils.data.DataLoader(valid, batch_size=64, sampler=valid_sampler)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "#Model\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(1024*3, 512*3).cuda(device)\n",
        "      self.fc2 = nn.Linear(512*3, 256*3).cuda(device)\n",
        "      self.fc3 = nn.Linear(256*3, 128*3).cuda(device)\n",
        "      self.fc4 = nn.Linear(128*3, 64*3).cuda(device)\n",
        "      self.fc5 = nn.Linear(64*3, 32*3).cuda(device)\n",
        "      self.fc6 = nn.Linear(32*3, 10).cuda(device)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 1024*3)\n",
        "      x.cuda(device)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = F.relu(self.fc4(x))\n",
        "      x = F.relu(self.fc5(x))\n",
        "      x = self.fc6(x)\n",
        "      return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = Net()\n",
        "\n",
        "#hyperparameter\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "#Train\n",
        "for epoch in range(1,101):\n",
        "  acc=0\n",
        "  train_loss = 0.0\n",
        "  for image, label in trainloader:\n",
        "    image, label = image.to(device), label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(image)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    acc += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    correct = 0\n",
        "    valid_loss = 0.0\n",
        "    for image, label in validloader:\n",
        "      image, label = image.to(device), label.to(device)\n",
        "      output = model(image)\n",
        "      loss = criterion(output, label)\n",
        "      valid_loss += loss.item()\n",
        "      vpred = output.argmax(dim=1, keepdim=True)\n",
        "      correct += vpred.eq(label.view_as(vpred)).sum().item()\n",
        "    print('Epoch:{}/{}, train_loss:{}, train_Accuracy:{}, valid_loss:{}, validation Accuracy: {}'.format(epoch, 100, train_loss / 45000, 100 * acc / 45000, valid_loss / 5000, 100 * correct / 5000))\n",
        "\n",
        "#Test acc\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for image, label in testloader:\n",
        "    image, label = image.to(device), label.to(device)\n",
        "    output = model(image)\n",
        "    tpred = output.argmax(dim=1, keepdim=True)\n",
        "    correct += tpred.eq(label.view_as(tpred)).sum().item()\n",
        "\n",
        "print('Test Accuracy: {}'.format(100 * correct / len(testloader.dataset)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch:10/100, train_loss:0.03598873875935872, train_Accuracy:13.102222222222222, valid_loss:0.03634411196708679, validation Accuracy: 14.3\n",
            "Epoch:20/100, train_loss:0.03585971216625637, train_Accuracy:21.72222222222222, valid_loss:0.03619255495071411, validation Accuracy: 23.18\n",
            "Epoch:30/100, train_loss:0.034541379822625055, train_Accuracy:19.435555555555556, valid_loss:0.03463901958465576, validation Accuracy: 20.18\n",
            "Epoch:40/100, train_loss:0.03183430882294973, train_Accuracy:23.626666666666665, valid_loss:0.03198616662025452, validation Accuracy: 24.74\n",
            "Epoch:50/100, train_loss:0.029635790440771314, train_Accuracy:28.982222222222223, valid_loss:0.029899160361289978, validation Accuracy: 29.54\n",
            "Epoch:60/100, train_loss:0.028214421060350207, train_Accuracy:33.111111111111114, valid_loss:0.02862076075077057, validation Accuracy: 33.74\n",
            "Epoch:70/100, train_loss:0.026873674676153394, train_Accuracy:36.51777777777778, valid_loss:0.02754126625061035, validation Accuracy: 36.2\n",
            "Epoch:80/100, train_loss:0.025063291104634604, train_Accuracy:41.004444444444445, valid_loss:0.026091749453544616, validation Accuracy: 40.16\n",
            "Epoch:90/100, train_loss:0.022992091364330714, train_Accuracy:45.58, valid_loss:0.024552354574203492, validation Accuracy: 44.04\n",
            "Epoch:100/100, train_loss:0.021065820778740776, train_Accuracy:50.13777777777778, valid_loss:0.024496435809135436, validation Accuracy: 45.68\n",
            "Test Accuracy: 45.34\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}